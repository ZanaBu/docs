---
title: "Genie Vision"
---
Not all knowledge lives in text.  
**Genie Vision** allows ProgramGenie to see what you see — interpreting images, screenshots, wireframes, or diagrams and turning them into structured, usable artefacts.

Upload an interface mockup, a whiteboard sketch, or even a screenshot of another system — Genie Vision instantly understands it and generates related **user stories, requirements, and test cases**.

<Note>Genie Vision bridges the gap between visual design and written documentation — where UX meets SDLC.</Note>

---

## Why Genie Vision Matters

Visual information is often lost between design and development teams. Genie Vision changes that by creating a **direct translation from image to insight**.

**Key advantages:**
- **Faster Handoffs:** Designers upload visuals — Genie generates structured stories automatically.  
- **Error Reduction:** No more misinterpretation between design and documentation.  
- **Full Traceability:** Every visual artefact links back to project requirements.  
- **Multi-Format Input:** Works with screenshots, Figma exports, PDFs, and even hand-drawn sketches.  
- **Automation-Ready:** Outputs link directly to Jira or Confluence, preserving visual context.

<Tip>From picture to project brief — Genie Vision makes every pixel count.</Tip>

---

## How It Works

<Columns cols={2}>
  <Card>
    **1. Upload or Capture** 
    Drag and drop an image, screenshot, or wireframe into Genie Vision.  
    Supported formats: PNG, JPG, PDF, Figma export, or Sketch.
  </Card>

  <Card>
    **2. Visual Understanding** 
    Genie identifies screens, UI elements, workflows, and text labels using AI-powered image analysis.
  </Card>

  <Card>
    **3. Artefact Generation** 
    Based on what it sees, Genie automatically creates corresponding **user stories**, **test cases**, and **requirements**.
  </Card>

  <Card>
    **4. Review & Sync** 
    You can refine descriptions, tag team members, and publish artefacts directly to Jira or other integrations.
  </Card>
</Columns>

<Note>All outputs remain editable — Genie Vision accelerates generation, but teams stay in control of final definitions.</Note>

---

## Example Use Case

A **telecom client** uploads screenshots of a mobile self-service app.  
Genie Vision analyzes each screen and produces:
- User stories (e.g., “As a customer, I want to view my usage summary.”)  
- Test cases validating buttons, fields, and actions  
- Wireframe summaries for client review  

Within minutes, the team has a complete, traceable documentation package connected to the visual source.

---

## Supported Inputs

| **Input Type** | **Description** | **Example Output** |
|----------------|----------------|--------------------|
| **UI Screenshot** | Genie detects layout, labels, and actions. | User stories for login, menu, or settings. |
| **Wireframe / Mockup** | Structural representation of interface. | Epics and stories per screen section. |
| **Diagram / Flowchart** | Logical or process flow visuals. | Sequential requirements or process documentation. |
| **PDF / Slide Deck** | Multi-screen or document-based design export. | Collated artefacts per page. |

---

## Best Practices

> - Upload clean, high-resolution images for best results.  
> - Group related screens (e.g., one flow per upload).  
> - Add short context notes before upload for better interpretation.  
> - Review generated artefacts — they can be fine-tuned or regenerated.  
> - Link visuals to related Epics for traceability.  

<Tip>Genie Vision doesn’t replace design — it connects it. The goal is faster understanding, not creative replacement.</Tip>

---

## Example Prompt

> “Generate user stories from this onboarding screen flow.”  
> *(Uploads three PNGs of mobile screens)*  

✅ Output:  
- “As a new user, I want to register using my email.”  
- “As a user, I want to verify my account via OTP.”  
- “As a user, I want to log in and see my welcome screen.”

---

## Related Features

- [Wireframes →](/features/wireframes)  
- [User Stories →](/features/userstories)  
- [Test Cases →](/features/testcases)  
- [Genie Chat →](/features/geniechat)

---

## FAQ

<AccordionGroup>

  <Accordion title="What kind of images does Genie Vision support?">
    PNG, JPG, PDF, and Figma/Sketch exports are all supported. High-contrast visuals give best results.
  </Accordion>

  <Accordion title="Can Genie Vision read text from screenshots?">
    Yes. Genie Vision uses OCR (Optical Character Recognition) to capture text labels, buttons, and messages.
  </Accordion>

  <Accordion title="Can it interpret complex diagrams or workflows?">
    Absolutely. Genie Vision identifies entities, relationships, and sequence flows to create logical artefacts.
  </Accordion>

  <Accordion title="Are generated outputs editable?">
    Yes. All generated artefacts — stories, tests, and requirements — can be reviewed, modified, or regenerated anytime.
  </Accordion>

  <Accordion title="Does Genie Vision store uploaded images?">
    Images are stored securely within your project workspace and linked only to their associated artefacts.
  </Accordion>

</AccordionGroup>
